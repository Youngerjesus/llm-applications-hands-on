{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autotrain-advanced==0.7.77\n",
      "  Downloading autotrain_advanced-0.7.77-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting albumentations==1.4.4 (from autotrain-advanced==0.7.77)\n",
      "  Downloading albumentations-1.4.4-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting codecarbon==2.3.5 (from autotrain-advanced==0.7.77)\n",
      "  Downloading codecarbon-2.3.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting datasets~=2.19.0 (from datasets[vision]~=2.19.0->autotrain-advanced==0.7.77)\n",
      "  Using cached datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate==0.4.1 (from autotrain-advanced==0.7.77)\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting ipadic==1.0.0 (from autotrain-advanced==0.7.77)\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jiwer==3.0.3 (from autotrain-advanced==0.7.77)\n",
      "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib==1.4.0 (from autotrain-advanced==0.7.77)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting loguru==0.7.2 (from autotrain-advanced==0.7.77)\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pandas==2.2.2 (from autotrain-advanced==0.7.77)\n",
      "  Downloading pandas-2.2.2.tar.gz (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk==3.8.1 (from autotrain-advanced==0.7.77)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting optuna==3.6.1 (from autotrain-advanced==0.7.77)\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting Pillow==10.3.0 (from autotrain-advanced==0.7.77)\n",
      "  Downloading pillow-10.3.0.tar.gz (46.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[21 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/jeongmin/PycharmProjects/llm-applications-hands-on/llm_env/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m353\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/jeongmin/PycharmProjects/llm-applications-hands-on/llm_env/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m335\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input['kwargs'])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/jeongmin/PycharmProjects/llm-applications-hands-on/llm_env/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m118\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/r4/w6gk0qbd6bd_sf7xj6nwdnxc0000gn/T/pip-build-env-rwgq36fc/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/r4/w6gk0qbd6bd_sf7xj6nwdnxc0000gn/T/pip-build-env-rwgq36fc/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/r4/w6gk0qbd6bd_sf7xj6nwdnxc0000gn/T/pip-build-env-rwgq36fc/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m33\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m27\u001b[0m, in \u001b[35mget_version\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mKeyError\u001b[0m: \u001b[35m'__version__'\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autotrain-advanced==0.7.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: autotrain\n"
     ]
    }
   ],
   "source": [
    "base_model = 'beomi/Yi-Ko-6B'\n",
    "finetuned_model = 'yi-ko-6b-text2sql'\n",
    "\n",
    "!autotrain llm \\\n",
    "--train \\\n",
    "--model {base_model} \\\n",
    "--project-name {finetuned_model} \\\n",
    "--data-path data/ \\\n",
    "--text-column text \\\n",
    "--lr 2e-4 \\\n",
    "--batch-size 8 \\\n",
    "--epochs 1 \\\n",
    "--block-size 1024 \\\n",
    "--warmup-ratio 0.1 \\\n",
    "--lora-r 16 \\\n",
    "--lora-alpha 32 \\\n",
    "--lora-dropout 0.05 \\\n",
    "--weight-decay 0.01 \\\n",
    "--gradient-accumulation 8 \\\n",
    "--mixed-precision fp16 \\\n",
    "--use-peft \\\n",
    "--quantization int4 \\\n",
    "--trainer sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA 어댑터 결합 및 허깅페이스 허브 업로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "model_name = base_model\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# LoRA와 기초 모델 파라미터 합치기\n",
    "# LoRA는 학습 시 메모리 효율성을 위해 기본 모델과 별도로 적은 수의 파라미터만 학습합니다. 그러나 추론 시에는 이를 병합해서 모두 메모리에 올려야 함. \n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, finetuned_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 토크나이저 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 허깅페이스 허브에 모델 및 토크나이저 저장\n",
    "model.push_to_hub(finetuned_model, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(finetuned_model, use_temp_dir=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
